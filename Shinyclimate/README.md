# Visualisation app 

## Aim

Enable visual analysis of APSIM outputs as maps

## Project set up and overview

- Reads data from a PostgreSQL database where APSIM outputs are stored
- Compares 2 possible scenarios as overlayed maps
- Displays distribution of variable values across modeled areas

## Contacts 

- John.Powell@niwa.co.nz (external developer collaborator)
- Hymmi.Kong@plantandfood.co.nz (PFR in-house collaborator)
- Eric.Burgueno@plantandfood.co.nz (PFR in-house collaborator)

# Docker and Docker Compose
The Docker stack files provide a quick and easy way to deploy and demo the ATLAS Shiny App for local development.

## Process overview  
The live version of the application is currently hosted at https://atlas.powerplant.pfr.co.nz/, which is an internal server at PFR. To update or modify the application, you need `ssh` access to that server.

Only the [ShinyDev](https://github.com/PlantandFoodResearch/ShinyClimateChange/tree/ShinyDev) branch from this repo is needed for updating the app. Refer to the following steps.

## Usage
1. Clone/Update the git repo
2. `cd ShinyApps`
3. `docker-compose down` (optional: in case you have an older version)
4. `docker-compose build` (optional: to test that the Docker image builds correctly or if you made changes to `app/creds.R` or other Shiny files. Do note that `docker-compose up` will build it automatically if it doesn't exist anyway)
5. `docker-compose up -d`
6. `docker rmi "oldimage_id"` to remove the previous image. usually with name 'none' _This can be tricky when child image present_
7.  Browse to https://atlas.powerplant.dev.pfr.co.nz/

## Hacking
- Database connection details are configured under `app/creds.R`. In the live instance, this file is bind-mounted from persistent storage to point to the live databases. In the development/local instances, the file is baked into the container image at build time.
- The `db*.sql.gz` databases in this repo contain example APSIM outputs as produced by the framework
- The db files can be generated by the command below (replace the `<>` brackets with the correct information)

```
$ pg_dump -O [-C] -U <username> -W -h <hostname> -d <dbname> | gzip > <dbname>.sql.gz
```

Note that the command above will wait for password input, but because of the `| gzip` you will not see the prompt. Just enter the password as usual.

Flags explained:  
* -O: removes references to the db "owner"
* -C: optional: adds "create database" statement to the backup file. This is important if you want to have multiple databases served by the same Docker container
* -U: username of the db
* -W: force pg_dump to prompt for a password before connecting to a database
* -h: host name
* -d: db name

If you would like to change the database name before compressing the backup file, you can do so with a one-liner like this one:

```
$ pg_dump -O -C -U <username> -W -h <hostname> -d <dbname> | sed 's/<dbname>/<new_dbname>/g' | gzip > <dbname>.sql.gz
```

More details about [`pg_dump` here](https://www.postgresql.org/docs/10/app-pgdump.html)

## Deploy app locally
If you do not have access to powerPlant or would like to run your own local instance, you can follow these steps on a Windows, MacOS, or Linux machine.

### Prerequisites

1. The latest version of [**Docker**](https://www.docker.com/) for your Operating System.
2. A compressed db file that contains the PostgreSQL data. Refer to the two examples in this repo.

### `docker-compose-dev.yml` explained

The application consists of two "services": the Shiny app itself, and the PostgreSQL database(s) with the APSIM outputs as created by the ATLAS framework. Multiple projects can be hosted in the same or in different database containers (for example, if you would like to try different versions of PostgreSQL to test for regressions). The databases are only accessed for reading by the App, so there's no risk using containers in this case.

The `docker-compose-dev.yml` file simplifies connecting the Shiny app to the PostgreSQL server(s) by creating an internal network for all of the containers listed under the `services:` section to "see" each other. But the Shiny app itself still needs to be configured with the hostname, database name, and credentials for all of the PostgreSQL databases it needs to connect to. This is done via the `app/creds.R` file. Because Docker sets a container's name as its hostname, the `host` line in `app/creds.R` needs to match the database container name you use in `docker-compose-dev.yml`. For example:

```
P007_CropNZ <- list(dbname = "postgres",
                     host = "dbP007Demo",
                     username = "postgres",
                     password = "password")
```

But default, Docker's `postgres` image imports databases using `postgres` as the database name, `postgres` as the username, and the password set via the `POSTGRES_PASSWORD` environment variable. If you changed any of these you will need to adjust `app/creds.R` accordingly. For example, if you are loading a database that was exported using `pg_dump -C`, you will need to specify the corresponding database name:

```
P007_CropNZ <- list(dbname = "P007_Demo",
                     host = "dbP007Demo",
                     username = "postgres",
                     password = "password")
```
### Deploy the app with MULTIPLE projects using separate database containers (default)

1. Clone this repository or download the files to your local machine. Make sure you are in the correct branch (it should contain the **ShinyApp** directory).
2. [Optional] If you want to customize the databases to connect to, open the `docker-compose.yml` file and edit the following sections:
  - `depends_on` in the `app` section: if you add, modify, or remove db containers. The list needs to match the db container names you use later on in the same file.
  - `db*` containers section: this is where you define all of the databases that the app will connect to. Remember that the name of the container must match with what's in the `depends_on`. You can change the version of PostgreSQL you're using, the password to connect to, etc. For more details refer to the [official documentation](https://github.com/docker-library/docs/blob/master/postgres/README.md) of the Docker's PostgreSQL image.
3. [Optional] If you made changes in step 2. above, update the `/app/creds.R` accordingly.
4. Open a Git GUI or other CLI terminals and navigate to the `/ShinyApp/` directory.
5. Follow the steps 4 - 5 in the **Usage** section above.
6. Browse to http://localhost:4242 to access your local instance.

For example, to add a new container for Project 6, one can copy an existing DB section and edit the necessary components:
```
  dbP006:
    image: postgres:10-alpine
    restart: unless-stopped
    environment:
      POSTGRES_PASSWORD: password123
    volumes:
      - "./dbP006.sql.gz:/docker-entrypoint-initdb.d/dbP006.sql.gz:z"
```
Now you need to update `app/creds.R` accordingly:

```
P006_SuperCropNZ <- list(dbname = "postgres",
		     host = "dbP006",
		     username = "postgres",
		     password = "password123")
```
Notice how we used `P006_SuperCropNZ` as the project name. You can change this freely and the name does not need to match the database name. We do use `P00*_PROJECTNAME` as a convention. Notice also how `host` and `password` match the container name and `POSTGRES_PASSWORD` as defined in `docker-compose.yml`.

### Deploy the app with a SINGLE or MULTIPLE projects using a single database container

If you only need a single database, you can remove all but one of the database containers defined in the `docker-compose-dev.yml` file, and update `app/creds.R` accordingly.

The Docker's `postgres` container doesn't automatically deal with multiple databases. If you want to import more than one into the same container, you need to ensure that you create the databases yourself and ensure that the database user (eg: `postgres` by default) has enough privileges on them. Here we present one way to achieve this but [different approaches](https://dev.to/bgord/multiple-postgres-databases-in-a-single-docker-container-417l) exist that you could also use.

The main pre-requisite is that you bind-mount multiple database backups created with the `pg_dump -O -C` options as shown above, into the `/docker-entrypoint-initdb.d/` directory inside the container. The database names must be unique or only the first one will be imported. The `-O` flag is optional, but ensures that the default user in the database container gains ownership of all the databases being imported, otherwise you will need to manually create the database users yourself, matching what the database exports expect.

1. Clone this repository or download the files to your local machine. Make sure you are in the correct branch (`develop` - it should contain the **ShinyApp** directory).
2. Customize the databases to connect to by opening the `docker-compose-dev.yml` file and editing the following sections:
  - `depends_on` in the `app` section: Leaving a single item that matches the db container name you use later on in the same file.
  - `db*` containers section: Remove all but one, and edit the `volumes:` list to include multiple backup files.
3. Since you made changes in step 2. above, update the `app/creds.R` accordingly.
4. Open a Git GUI or other CLI terminals and navigate to the `ShinyApp/` directory.
5. Run `docker-compose -f docker-compose-dev.yml up -d` to start the stack.
6. Browse to http://localhost:8000 to access your local instance.

For example, to have a single container for Projects 6 and 7, you can edit the DB section as follows:
```
  db:
    image: postgres:10-alpine
    restart: unless-stopped
    environment:
      POSTGRES_PASSWORD: password
    volumes:
      - "./dbP006.sql.gz:/docker-entrypoint-initdb.d/dbP006.sql.gz:z"
      - "./dbP007.sql.gz:/docker-entrypoint-initdb.d/dbP007.sql.gz:z"
```
Now you need to update `app/creds.R` accordingly:

```
P006_SuperCropNZ <- list(dbname = "dbP006",
		     host = "db",
		     username = "postgres",
		     password = "password")
P007_AnotherCropNZ <- list(dbname = "dbP007",
		     host = "db",
		     username = "postgres",
		     password = "password")

```
Notice how we use a single `host`: `"db"`. This matches the container name as defined in `docker-compose-dev.yml`.

### Add server in pgAdmin to browser dbs

Inspired by this [blog](https://linuxhint.com/postgresql_docker/)

### Some tips

1. Large db files will take a bit time to be restored on the PostgreSQL image. One could check if the db is ready by looking at the container logs (`docker-compose logs` on the CLI, or by clicking the db container on the Docker dashboard).
2. One can use the docker Dashboard to do basic control such as `stop/restart/remove` containers.  
3. One can also use the `CLI` inside each container to verify the db and R. 

## Common issues when build and compose up 

- Error writing to output file - write (28: No space left on device)  
probably because too many dangling images occupied too much space.  
https://stackoverflow.com/questions/59060954/error-writing-to-output-file-write-28-no-space-left-on-device
